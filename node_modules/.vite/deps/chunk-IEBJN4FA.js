import {
  AutoReleaseWorkerPool
} from "./chunk-QCIHLJPD.js";
import {
  Tools
} from "./chunk-NWYBHPBZ.js";

// node_modules/@babylonjs/core/Meshes/Compression/dracoCompressionWorker.js
function EncodeMesh(module, attributes, indices, options) {
  const encoderModule = module;
  let encoder = null;
  let meshBuilder = null;
  let mesh = null;
  let encodedNativeBuffer = null;
  const attributeIDs = {};
  const positionAttribute = attributes.find((a) => a.dracoName === "POSITION");
  if (!positionAttribute) {
    throw new Error("Position attribute is required for Draco encoding");
  }
  if (!indices) {
    const positionVerticesCount = positionAttribute.data.length / positionAttribute.size;
    indices = new (positionVerticesCount > 65535 ? Uint32Array : Uint16Array)(positionVerticesCount);
    for (let i = 0; i < positionVerticesCount; i++) {
      indices[i] = i;
    }
  }
  try {
    encoder = new encoderModule.Encoder();
    meshBuilder = new encoderModule.MeshBuilder();
    mesh = new encoderModule.Mesh();
    meshBuilder.AddFacesToMesh(mesh, indices.length / 3, indices);
    const addAttributeMap = /* @__PURE__ */ new Map([
      [Float32Array, (mb, m, a, c, s, d) => mb.AddFloatAttribute(m, a, c, s, d)],
      [Uint32Array, (mb, m, a, c, s, d) => mb.AddUInt32Attribute(m, a, c, s, d)],
      [Uint16Array, (mb, m, a, c, s, d) => mb.AddUInt16Attribute(m, a, c, s, d)],
      [Uint8Array, (mb, m, a, c, s, d) => mb.AddUInt8Attribute(m, a, c, s, d)],
      [Int32Array, (mb, m, a, c, s, d) => mb.AddInt32Attribute(m, a, c, s, d)],
      [Int16Array, (mb, m, a, c, s, d) => mb.AddInt16Attribute(m, a, c, s, d)],
      [Int8Array, (mb, m, a, c, s, d) => mb.AddInt8Attribute(m, a, c, s, d)]
    ]);
    for (const attribute of attributes) {
      if (attribute.data instanceof Uint8ClampedArray) {
        attribute.data = new Uint8Array(attribute.data);
      }
      const addAttribute = addAttributeMap.get(attribute.data.constructor);
      const verticesCount = attribute.data.length / attribute.size;
      attributeIDs[attribute.kind] = addAttribute(meshBuilder, mesh, encoderModule[attribute.dracoName], verticesCount, attribute.size, attribute.data);
      if (options.quantizationBits && options.quantizationBits[attribute.dracoName]) {
        encoder.SetAttributeQuantization(encoderModule[attribute.dracoName], options.quantizationBits[attribute.dracoName]);
      }
    }
    if (options.method) {
      encoder.SetEncodingMethod(encoderModule[options.method]);
    }
    if (options.encodeSpeed !== void 0 && options.decodeSpeed !== void 0) {
      encoder.SetSpeedOptions(options.encodeSpeed, options.decodeSpeed);
    }
    encodedNativeBuffer = new encoderModule.DracoInt8Array();
    const encodedLength = encoder.EncodeMeshToDracoBuffer(mesh, encodedNativeBuffer);
    if (encodedLength <= 0) {
      throw new Error("Draco encoding failed.");
    }
    const encodedData = new Int8Array(encodedLength);
    for (let i = 0; i < encodedLength; i++) {
      encodedData[i] = encodedNativeBuffer.GetValue(i);
    }
    return { data: encodedData, attributeIds: attributeIDs };
  } finally {
    if (mesh) {
      encoderModule.destroy(mesh);
    }
    if (meshBuilder) {
      encoderModule.destroy(meshBuilder);
    }
    if (encoder) {
      encoderModule.destroy(encoder);
    }
    if (encodedNativeBuffer) {
      encoderModule.destroy(encodedNativeBuffer);
    }
  }
}
function EncoderWorkerFunction() {
  let encoderPromise;
  onmessage = (event) => {
    const message = event.data;
    switch (message.id) {
      case "init": {
        if (message.url) {
          importScripts(message.url);
        }
        const initEncoderObject = message.wasmBinary ? { wasmBinary: message.wasmBinary } : {};
        encoderPromise = DracoEncoderModule(initEncoderObject);
        postMessage({ id: "initDone" });
        break;
      }
      case "encodeMesh": {
        if (!encoderPromise) {
          throw new Error("Draco encoder module is not available");
        }
        encoderPromise.then((encoder) => {
          const result = EncodeMesh(encoder, message.attributes, message.indices, message.options);
          postMessage({ id: "encodeMeshDone", encodedMeshData: result }, result ? [result.data.buffer] : void 0);
        });
        break;
      }
    }
  };
}
function DecodeMesh(module, data, attributeIDs, onIndicesData, onAttributeData) {
  const decoderModule = module;
  let decoder = null;
  let buffer = null;
  let geometry = null;
  try {
    decoder = new decoderModule.Decoder();
    buffer = new decoderModule.DecoderBuffer();
    buffer.Init(data, data.byteLength);
    let status;
    const type = decoder.GetEncodedGeometryType(buffer);
    switch (type) {
      case decoderModule.TRIANGULAR_MESH: {
        const mesh = new decoderModule.Mesh();
        status = decoder.DecodeBufferToMesh(buffer, mesh);
        if (!status.ok() || mesh.ptr === 0) {
          throw new Error(status.error_msg());
        }
        const numFaces = mesh.num_faces();
        const numIndices = numFaces * 3;
        const byteLength = numIndices * 4;
        const ptr = decoderModule._malloc(byteLength);
        try {
          decoder.GetTrianglesUInt32Array(mesh, byteLength, ptr);
          const indices = new Uint32Array(numIndices);
          indices.set(new Uint32Array(decoderModule.HEAPF32.buffer, ptr, numIndices));
          onIndicesData(indices);
        } finally {
          decoderModule._free(ptr);
        }
        geometry = mesh;
        break;
      }
      case decoderModule.POINT_CLOUD: {
        const pointCloud = new decoderModule.PointCloud();
        status = decoder.DecodeBufferToPointCloud(buffer, pointCloud);
        if (!status.ok() || !pointCloud.ptr) {
          throw new Error(status.error_msg());
        }
        geometry = pointCloud;
        break;
      }
      default: {
        throw new Error(`Invalid geometry type ${type}`);
      }
    }
    const numPoints = geometry.num_points();
    const processAttribute = (decoder2, geometry2, kind, attribute) => {
      const dataType = attribute.data_type();
      const numComponents = attribute.num_components();
      const normalized = attribute.normalized();
      const byteStride = attribute.byte_stride();
      const byteOffset = attribute.byte_offset();
      const dataTypeInfo = {
        [decoderModule.DT_FLOAT32]: { typedArrayConstructor: Float32Array, heap: decoderModule.HEAPF32 },
        [decoderModule.DT_INT8]: { typedArrayConstructor: Int8Array, heap: decoderModule.HEAP8 },
        [decoderModule.DT_INT16]: { typedArrayConstructor: Int16Array, heap: decoderModule.HEAP16 },
        [decoderModule.DT_INT32]: { typedArrayConstructor: Int32Array, heap: decoderModule.HEAP32 },
        [decoderModule.DT_UINT8]: { typedArrayConstructor: Uint8Array, heap: decoderModule.HEAPU8 },
        [decoderModule.DT_UINT16]: { typedArrayConstructor: Uint16Array, heap: decoderModule.HEAPU16 },
        [decoderModule.DT_UINT32]: { typedArrayConstructor: Uint32Array, heap: decoderModule.HEAPU32 }
      };
      const info = dataTypeInfo[dataType];
      if (!info) {
        throw new Error(`Invalid data type ${dataType}`);
      }
      const numValues = numPoints * numComponents;
      const byteLength = numValues * info.typedArrayConstructor.BYTES_PER_ELEMENT;
      const ptr = decoderModule._malloc(byteLength);
      try {
        decoder2.GetAttributeDataArrayForAllPoints(geometry2, attribute, dataType, byteLength, ptr);
        const data2 = new info.typedArrayConstructor(info.heap.buffer, ptr, numValues);
        onAttributeData(kind, data2.slice(), numComponents, byteOffset, byteStride, normalized);
      } finally {
        decoderModule._free(ptr);
      }
    };
    if (attributeIDs) {
      for (const kind in attributeIDs) {
        const id = attributeIDs[kind];
        const attribute = decoder.GetAttributeByUniqueId(geometry, id);
        processAttribute(decoder, geometry, kind, attribute);
      }
    } else {
      const dracoAttributeTypes = {
        position: decoderModule.POSITION,
        normal: decoderModule.NORMAL,
        color: decoderModule.COLOR,
        uv: decoderModule.TEX_COORD
      };
      for (const kind in dracoAttributeTypes) {
        const id = decoder.GetAttributeId(geometry, dracoAttributeTypes[kind]);
        if (id !== -1) {
          const attribute = decoder.GetAttribute(geometry, id);
          processAttribute(decoder, geometry, kind, attribute);
        }
      }
    }
    return numPoints;
  } finally {
    if (geometry) {
      decoderModule.destroy(geometry);
    }
    if (buffer) {
      decoderModule.destroy(buffer);
    }
    if (decoder) {
      decoderModule.destroy(decoder);
    }
  }
}
function DecoderWorkerFunction() {
  let decoderPromise;
  onmessage = (event) => {
    const message = event.data;
    switch (message.id) {
      case "init": {
        if (message.url) {
          importScripts(message.url);
        }
        const initDecoderObject = message.wasmBinary ? { wasmBinary: message.wasmBinary } : {};
        decoderPromise = DracoDecoderModule(initDecoderObject);
        postMessage({ id: "initDone" });
        break;
      }
      case "decodeMesh": {
        if (!decoderPromise) {
          throw new Error("Draco decoder module is not available");
        }
        decoderPromise.then((decoder) => {
          const numPoints = DecodeMesh(decoder, message.dataView, message.attributes, (indices) => {
            postMessage({ id: "indices", data: indices }, [indices.buffer]);
          }, (kind, data, size, offset, stride, normalized) => {
            postMessage({ id: "attribute", kind, data, size, byteOffset: offset, byteStride: stride, normalized }, [data.buffer]);
          });
          postMessage({ id: "decodeMeshDone", totalVertices: numPoints });
        });
        break;
      }
    }
  };
}
async function initializeWebWorker(worker, wasmBinary, moduleUrl) {
  return await new Promise((resolve, reject) => {
    const onError = (error) => {
      worker.removeEventListener("error", onError);
      worker.removeEventListener("message", onMessage);
      reject(error);
    };
    const onMessage = (event) => {
      if (event.data.id === "initDone") {
        worker.removeEventListener("error", onError);
        worker.removeEventListener("message", onMessage);
        resolve(worker);
      }
    };
    worker.addEventListener("error", onError);
    worker.addEventListener("message", onMessage);
    if (!wasmBinary) {
      worker.postMessage({
        id: "init",
        url: moduleUrl
      });
    } else {
      const clone = wasmBinary.slice(0);
      worker.postMessage({
        id: "init",
        url: moduleUrl,
        wasmBinary: clone
      }, [clone]);
    }
  });
}

// node_modules/@babylonjs/core/Meshes/Compression/dracoCodec.js
function _GetDefaultNumWorkers() {
  if (typeof navigator !== "object" || !navigator.hardwareConcurrency) {
    return 1;
  }
  return Math.min(Math.floor(navigator.hardwareConcurrency * 0.5), 4);
}
function _IsConfigurationAvailable(config) {
  return !!(config.wasmUrl && (config.wasmBinary || config.wasmBinaryUrl) && typeof WebAssembly === "object" || config.fallbackUrl);
}
var DracoCodec = class {
  /**
   * Constructor
   * @param configuration The configuration for the DracoCodec instance.
   */
  constructor(configuration) {
    if (configuration.workerPool) {
      this._workerPoolPromise = Promise.resolve(configuration.workerPool);
      return;
    }
    const wasmBinaryProvided = configuration.wasmBinary;
    const numberOfWorkers = configuration.numWorkers ?? _GetDefaultNumWorkers();
    const useWorkers = numberOfWorkers && typeof Worker === "function" && typeof URL === "function";
    const urlNeeded = useWorkers || !configuration.jsModule;
    const codecInfo = configuration.wasmUrl && configuration.wasmBinaryUrl && typeof WebAssembly === "object" ? {
      url: urlNeeded ? Tools.GetBabylonScriptURL(configuration.wasmUrl, true) : "",
      wasmBinaryPromise: wasmBinaryProvided ? Promise.resolve(wasmBinaryProvided) : Tools.LoadFileAsync(Tools.GetBabylonScriptURL(configuration.wasmBinaryUrl, true))
    } : {
      url: urlNeeded ? Tools.GetBabylonScriptURL(configuration.fallbackUrl) : "",
      wasmBinaryPromise: Promise.resolve(void 0)
    };
    if (useWorkers) {
      this._workerPoolPromise = codecInfo.wasmBinaryPromise.then((wasmBinary) => {
        const workerContent = this._getWorkerContent();
        const workerBlobUrl = URL.createObjectURL(new Blob([workerContent], { type: "application/javascript" }));
        return new AutoReleaseWorkerPool(numberOfWorkers, () => {
          const worker = new Worker(workerBlobUrl);
          return initializeWebWorker(worker, wasmBinary, codecInfo.url);
        });
      });
    } else {
      this._modulePromise = codecInfo.wasmBinaryPromise.then(async (wasmBinary) => {
        if (!this._isModuleAvailable()) {
          if (!configuration.jsModule) {
            if (!codecInfo.url) {
              throw new Error("Draco codec module is not available");
            }
            await Tools.LoadBabylonScriptAsync(codecInfo.url);
          }
        }
        return await this._createModuleAsync(wasmBinary, configuration.jsModule);
      });
    }
  }
  /**
   * Returns a promise that resolves when ready. Call this manually to ensure the draco codec is ready before use.
   * @returns a promise that resolves when ready
   */
  async whenReadyAsync() {
    if (this._workerPoolPromise) {
      await this._workerPoolPromise;
      return;
    }
    if (this._modulePromise) {
      await this._modulePromise;
      return;
    }
  }
  /**
   * Stop all async operations and release resources.
   */
  dispose() {
    if (this._workerPoolPromise) {
      this._workerPoolPromise.then((workerPool) => {
        workerPool.dispose();
      });
    }
    delete this._workerPoolPromise;
    delete this._modulePromise;
  }
};

export {
  EncodeMesh,
  EncoderWorkerFunction,
  DecodeMesh,
  DecoderWorkerFunction,
  _GetDefaultNumWorkers,
  _IsConfigurationAvailable,
  DracoCodec
};
//# sourceMappingURL=chunk-IEBJN4FA.js.map
